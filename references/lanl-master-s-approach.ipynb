{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from tqdm import tqdm_notebook\n",
    "import datetime\n",
    "import time\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "from tensorflow import keras\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_X_0 = pd.read_csv(\"../input/lanl-masters-features-creating-0/train_X_features_865.csv\")\n",
    "train_X_1 = pd.read_csv(\"../input/lanl-masters-features-creating-1/train_X_features_865.csv\")\n",
    "y_0 = pd.read_csv(\"../input/lanl-masters-features-creating-0/train_y.csv\", index_col=False,  header=None)\n",
    "y_1 = pd.read_csv(\"../input/lanl-masters-features-creating-1/train_y.csv\", index_col=False,  header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 865)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFT_Mag_01q0</th>\n",
       "      <th>FFT_Mag_10q0</th>\n",
       "      <th>FFT_Mag_90q0</th>\n",
       "      <th>FFT_Mag_99q0</th>\n",
       "      <th>FFT_Mag_mean0</th>\n",
       "      <th>FFT_Mag_std0</th>\n",
       "      <th>FFT_Mag_max0</th>\n",
       "      <th>FFT_Phz_mean0</th>\n",
       "      <th>FFT_Phz_std0</th>\n",
       "      <th>FFT_Mag_01q2500</th>\n",
       "      <th>...</th>\n",
       "      <th>std_roll_mean_1000</th>\n",
       "      <th>max_roll_mean_1000</th>\n",
       "      <th>min_roll_mean_1000</th>\n",
       "      <th>q01_roll_mean_1000</th>\n",
       "      <th>q05_roll_mean_1000</th>\n",
       "      <th>q95_roll_mean_1000</th>\n",
       "      <th>q99_roll_mean_1000</th>\n",
       "      <th>av_change_abs_roll_mean_1000</th>\n",
       "      <th>av_change_rate_roll_mean_1000</th>\n",
       "      <th>abs_max_roll_mean_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.836711</td>\n",
       "      <td>421.371206</td>\n",
       "      <td>3837.759402</td>\n",
       "      <td>6112.131639</td>\n",
       "      <td>1739.925798</td>\n",
       "      <td>1385.814449</td>\n",
       "      <td>9064.175486</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>0.910909</td>\n",
       "      <td>417.854520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211731</td>\n",
       "      <td>5.464</td>\n",
       "      <td>3.769</td>\n",
       "      <td>4.301</td>\n",
       "      <td>4.401</td>\n",
       "      <td>5.116</td>\n",
       "      <td>5.262</td>\n",
       "      <td>1.409396e-06</td>\n",
       "      <td>74648.999921</td>\n",
       "      <td>5.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.732839</td>\n",
       "      <td>392.456548</td>\n",
       "      <td>2250.212819</td>\n",
       "      <td>3824.489952</td>\n",
       "      <td>1231.293809</td>\n",
       "      <td>828.294402</td>\n",
       "      <td>9080.893195</td>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.915573</td>\n",
       "      <td>305.137857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248184</td>\n",
       "      <td>5.801</td>\n",
       "      <td>4.243</td>\n",
       "      <td>4.506</td>\n",
       "      <td>4.685</td>\n",
       "      <td>5.498</td>\n",
       "      <td>5.659</td>\n",
       "      <td>7.442953e-06</td>\n",
       "      <td>74397.510027</td>\n",
       "      <td>5.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.434758</td>\n",
       "      <td>369.227304</td>\n",
       "      <td>1825.186779</td>\n",
       "      <td>3035.388361</td>\n",
       "      <td>1043.817464</td>\n",
       "      <td>661.241082</td>\n",
       "      <td>8666.843710</td>\n",
       "      <td>-0.007041</td>\n",
       "      <td>0.904811</td>\n",
       "      <td>207.531656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217408</td>\n",
       "      <td>4.764</td>\n",
       "      <td>3.526</td>\n",
       "      <td>3.702</td>\n",
       "      <td>3.786</td>\n",
       "      <td>4.507</td>\n",
       "      <td>4.604</td>\n",
       "      <td>8.389262e-07</td>\n",
       "      <td>74227.207542</td>\n",
       "      <td>4.764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.608863</td>\n",
       "      <td>392.794334</td>\n",
       "      <td>2468.215191</td>\n",
       "      <td>4139.927445</td>\n",
       "      <td>1271.285220</td>\n",
       "      <td>873.069679</td>\n",
       "      <td>9043.242078</td>\n",
       "      <td>-0.018745</td>\n",
       "      <td>0.904419</td>\n",
       "      <td>258.196842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244447</td>\n",
       "      <td>5.302</td>\n",
       "      <td>2.819</td>\n",
       "      <td>3.206</td>\n",
       "      <td>3.418</td>\n",
       "      <td>4.248</td>\n",
       "      <td>4.354</td>\n",
       "      <td>1.046980e-06</td>\n",
       "      <td>74415.594773</td>\n",
       "      <td>5.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.265220</td>\n",
       "      <td>444.217367</td>\n",
       "      <td>5397.274335</td>\n",
       "      <td>8740.417592</td>\n",
       "      <td>2212.343813</td>\n",
       "      <td>2080.628283</td>\n",
       "      <td>20996.324962</td>\n",
       "      <td>-0.017078</td>\n",
       "      <td>0.912532</td>\n",
       "      <td>660.563845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284440</td>\n",
       "      <td>5.657</td>\n",
       "      <td>3.187</td>\n",
       "      <td>3.872</td>\n",
       "      <td>4.037</td>\n",
       "      <td>4.953</td>\n",
       "      <td>5.190</td>\n",
       "      <td>4.496644e-07</td>\n",
       "      <td>74234.314526</td>\n",
       "      <td>5.657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 865 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFT_Mag_01q0  FFT_Mag_10q0  FFT_Mag_90q0  FFT_Mag_99q0  FFT_Mag_mean0  \\\n",
       "0    135.836711    421.371206   3837.759402   6112.131639    1739.925798   \n",
       "1    124.732839    392.456548   2250.212819   3824.489952    1231.293809   \n",
       "2    106.434758    369.227304   1825.186779   3035.388361    1043.817464   \n",
       "3    120.608863    392.794334   2468.215191   4139.927445    1271.285220   \n",
       "4    132.265220    444.217367   5397.274335   8740.417592    2212.343813   \n",
       "\n",
       "   FFT_Mag_std0  FFT_Mag_max0  FFT_Phz_mean0  FFT_Phz_std0  FFT_Mag_01q2500  \\\n",
       "0   1385.814449   9064.175486      -0.000510      0.910909       417.854520   \n",
       "1    828.294402   9080.893195       0.023934      0.915573       305.137857   \n",
       "2    661.241082   8666.843710      -0.007041      0.904811       207.531656   \n",
       "3    873.069679   9043.242078      -0.018745      0.904419       258.196842   \n",
       "4   2080.628283  20996.324962      -0.017078      0.912532       660.563845   \n",
       "\n",
       "            ...            std_roll_mean_1000  max_roll_mean_1000  \\\n",
       "0           ...                      0.211731               5.464   \n",
       "1           ...                      0.248184               5.801   \n",
       "2           ...                      0.217408               4.764   \n",
       "3           ...                      0.244447               5.302   \n",
       "4           ...                      0.284440               5.657   \n",
       "\n",
       "   min_roll_mean_1000  q01_roll_mean_1000  q05_roll_mean_1000  \\\n",
       "0               3.769               4.301               4.401   \n",
       "1               4.243               4.506               4.685   \n",
       "2               3.526               3.702               3.786   \n",
       "3               2.819               3.206               3.418   \n",
       "4               3.187               3.872               4.037   \n",
       "\n",
       "   q95_roll_mean_1000  q99_roll_mean_1000  av_change_abs_roll_mean_1000  \\\n",
       "0               5.116               5.262                  1.409396e-06   \n",
       "1               5.498               5.659                  7.442953e-06   \n",
       "2               4.507               4.604                  8.389262e-07   \n",
       "3               4.248               4.354                  1.046980e-06   \n",
       "4               4.953               5.190                  4.496644e-07   \n",
       "\n",
       "   av_change_rate_roll_mean_1000  abs_max_roll_mean_1000  \n",
       "0                   74648.999921                   5.464  \n",
       "1                   74397.510027                   5.801  \n",
       "2                   74227.207542                   4.764  \n",
       "3                   74415.594773                   5.302  \n",
       "4                   74234.314526                   5.657  \n",
       "\n",
       "[5 rows x 865 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = pd.concat([train_X_0, train_X_1], axis=0)\n",
    "train_X = train_X.reset_index(drop=True)\n",
    "print(train_X.shape)\n",
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.concat([y_0, y_1], axis=0)\n",
    "y = y.reset_index(drop=True)\n",
    "y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 865)\n",
      "(33000, 1)\n",
      "(2624, 865)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(y.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.Series(y[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "test_X = pd.read_csv(\"../input/lanl-masters-features-creating-0/test_X_features_10.csv\")\n",
    "del test_X[\"seg_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_columns = train_X.columns\n",
    "\n",
    "train_X[train_columns] = scaler.fit_transform(train_X[train_columns])\n",
    "test_X[train_columns] = scaler.transform(test_X[train_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = train_X.columns\n",
    "\n",
    "# df = pd.concat([train_X, test_X[cols]], axis=0)\n",
    "# df = df.reset_index(drop=True)\n",
    "# df[cols] = np.round(df.values, 3)\n",
    "\n",
    "# for col in cols:\n",
    "#     df[col+\"_count\"] = df[col].map(df[col].value_counts())\n",
    "    \n",
    "# count_cols = [i for i in df.columns if \"_count\" in i]\n",
    "\n",
    "# train_X = pd.concat([train_X, df.loc[:40000-1, count_cols]], axis=1)\n",
    "# test_X = pd.concat([test_X, df.loc[40000:, count_cols].reset_index(drop=True)], axis=1)\n",
    "# train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_columns = train_X.columns\n",
    "n_fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "0:\tlearn: 5.6534251\ttest: 5.7103149\tbest: 5.7103149 (0)\ttotal: 67.4ms\tremaining: 28m 5s\n",
      "2500:\tlearn: 1.6530211\ttest: 1.7309088\tbest: 1.7309088 (2500)\ttotal: 2m 36s\tremaining: 23m 25s\n",
      "5000:\tlearn: 1.4259490\ttest: 1.5684751\tbest: 1.5684751 (5000)\ttotal: 5m 15s\tremaining: 21m\n",
      "7500:\tlearn: 1.2678242\ttest: 1.4671433\tbest: 1.4671433 (7500)\ttotal: 7m 56s\tremaining: 18m 31s\n",
      "10000:\tlearn: 1.1491418\ttest: 1.3998904\tbest: 1.3998904 (10000)\ttotal: 10m 38s\tremaining: 15m 56s\n",
      "12500:\tlearn: 1.0529444\ttest: 1.3500095\tbest: 1.3500095 (12500)\ttotal: 13m 19s\tremaining: 13m 19s\n",
      "15000:\tlearn: 0.9738277\ttest: 1.3117460\tbest: 1.3117415 (14999)\ttotal: 16m 1s\tremaining: 10m 40s\n",
      "17500:\tlearn: 0.9049903\ttest: 1.2806047\tbest: 1.2806043 (17499)\ttotal: 18m 44s\tremaining: 8m 1s\n",
      "20000:\tlearn: 0.8455384\ttest: 1.2553391\tbest: 1.2553378 (19998)\ttotal: 21m 26s\tremaining: 5m 21s\n",
      "22500:\tlearn: 0.7927802\ttest: 1.2344988\tbest: 1.2344988 (22500)\ttotal: 24m 9s\tremaining: 2m 41s\n",
      "24999:\tlearn: 0.7474378\ttest: 1.2174123\tbest: 1.2174123 (24999)\ttotal: 26m 52s\tremaining: 0us\n",
      "bestTest = 1.217412257\n",
      "bestIteration = 24999\n",
      "Shrink model to first 25000 iterations.\n",
      "fold 1\n",
      "0:\tlearn: 5.6701746\ttest: 5.6433215\tbest: 5.6433215 (0)\ttotal: 64.7ms\tremaining: 26m 56s\n",
      "2500:\tlearn: 1.6436787\ttest: 1.7643410\tbest: 1.7643410 (2500)\ttotal: 2m 33s\tremaining: 22m 59s\n",
      "5000:\tlearn: 1.4112183\ttest: 1.6054606\tbest: 1.6054606 (5000)\ttotal: 5m 9s\tremaining: 20m 38s\n",
      "7500:\tlearn: 1.2588292\ttest: 1.5112092\tbest: 1.5112092 (7500)\ttotal: 7m 46s\tremaining: 18m 8s\n",
      "10000:\tlearn: 1.1449478\ttest: 1.4468182\tbest: 1.4468182 (10000)\ttotal: 10m 24s\tremaining: 15m 37s\n",
      "12500:\tlearn: 1.0521216\ttest: 1.4001861\tbest: 1.4001861 (12500)\ttotal: 13m 3s\tremaining: 13m 3s\n",
      "15000:\tlearn: 0.9755190\ttest: 1.3639190\tbest: 1.3639190 (15000)\ttotal: 15m 44s\tremaining: 10m 29s\n",
      "17500:\tlearn: 0.9091893\ttest: 1.3351450\tbest: 1.3351450 (17500)\ttotal: 18m 25s\tremaining: 7m 53s\n",
      "20000:\tlearn: 0.8519488\ttest: 1.3113030\tbest: 1.3112886 (19998)\ttotal: 21m 6s\tremaining: 5m 16s\n",
      "22500:\tlearn: 0.8008129\ttest: 1.2904032\tbest: 1.2904032 (22500)\ttotal: 23m 48s\tremaining: 2m 38s\n",
      "24999:\tlearn: 0.7555409\ttest: 1.2732681\tbest: 1.2732681 (24999)\ttotal: 26m 29s\tremaining: 0us\n",
      "bestTest = 1.273268081\n",
      "bestIteration = 24999\n",
      "Shrink model to first 25000 iterations.\n",
      "fold 2\n",
      "0:\tlearn: 5.6641525\ttest: 5.6673538\tbest: 5.6673538 (0)\ttotal: 61.6ms\tremaining: 25m 38s\n",
      "2500:\tlearn: 1.6487439\ttest: 1.7258536\tbest: 1.7258536 (2500)\ttotal: 2m 36s\tremaining: 23m 32s\n",
      "5000:\tlearn: 1.4170111\ttest: 1.5718985\tbest: 1.5718985 (5000)\ttotal: 5m 17s\tremaining: 21m 9s\n",
      "7500:\tlearn: 1.2649957\ttest: 1.4794013\tbest: 1.4794013 (7500)\ttotal: 7m 57s\tremaining: 18m 33s\n",
      "10000:\tlearn: 1.1463902\ttest: 1.4127919\tbest: 1.4127919 (10000)\ttotal: 10m 37s\tremaining: 15m 56s\n",
      "12500:\tlearn: 1.0528201\ttest: 1.3653945\tbest: 1.3653920 (12499)\ttotal: 13m 18s\tremaining: 13m 18s\n",
      "15000:\tlearn: 0.9747829\ttest: 1.3292729\tbest: 1.3292729 (15000)\ttotal: 15m 59s\tremaining: 10m 39s\n",
      "17500:\tlearn: 0.9078143\ttest: 1.2984714\tbest: 1.2984714 (17500)\ttotal: 18m 42s\tremaining: 8m\n",
      "20000:\tlearn: 0.8491734\ttest: 1.2729822\tbest: 1.2729822 (20000)\ttotal: 21m 24s\tremaining: 5m 21s\n",
      "22500:\tlearn: 0.7982886\ttest: 1.2523263\tbest: 1.2523263 (22500)\ttotal: 24m 7s\tremaining: 2m 40s\n",
      "24999:\tlearn: 0.7542776\ttest: 1.2365861\tbest: 1.2365515 (24988)\ttotal: 26m 52s\tremaining: 0us\n",
      "bestTest = 1.236551477\n",
      "bestIteration = 24988\n",
      "Shrink model to first 24989 iterations.\n",
      "fold 3\n",
      "0:\tlearn: 5.6649888\ttest: 5.6640720\tbest: 5.6640720 (0)\ttotal: 64.7ms\tremaining: 26m 58s\n",
      "2500:\tlearn: 1.6564116\ttest: 1.7154392\tbest: 1.7154392 (2500)\ttotal: 2m 36s\tremaining: 23m 29s\n",
      "5000:\tlearn: 1.4282105\ttest: 1.5616528\tbest: 1.5616528 (5000)\ttotal: 5m 15s\tremaining: 21m 2s\n",
      "7500:\tlearn: 1.2783434\ttest: 1.4708185\tbest: 1.4708156 (7499)\ttotal: 7m 55s\tremaining: 18m 30s\n",
      "10000:\tlearn: 1.1601873\ttest: 1.4049898\tbest: 1.4049898 (10000)\ttotal: 10m 36s\tremaining: 15m 54s\n",
      "12500:\tlearn: 1.0665683\ttest: 1.3560544\tbest: 1.3560544 (12500)\ttotal: 13m 16s\tremaining: 13m 16s\n",
      "15000:\tlearn: 0.9887755\ttest: 1.3185702\tbest: 1.3185702 (15000)\ttotal: 15m 59s\tremaining: 10m 39s\n",
      "17500:\tlearn: 0.9218902\ttest: 1.2875934\tbest: 1.2875934 (17500)\ttotal: 18m 41s\tremaining: 8m\n",
      "20000:\tlearn: 0.8635684\ttest: 1.2625651\tbest: 1.2625633 (19999)\ttotal: 21m 25s\tremaining: 5m 21s\n",
      "22500:\tlearn: 0.8121896\ttest: 1.2405642\tbest: 1.2405642 (22500)\ttotal: 24m 7s\tremaining: 2m 40s\n",
      "24999:\tlearn: 0.7668328\ttest: 1.2225655\tbest: 1.2225655 (24999)\ttotal: 26m 50s\tremaining: 0us\n",
      "bestTest = 1.222565548\n",
      "bestIteration = 24999\n",
      "Shrink model to first 25000 iterations.\n",
      "fold 4\n",
      "0:\tlearn: 5.6712595\ttest: 5.6389583\tbest: 5.6389583 (0)\ttotal: 65.4ms\tremaining: 27m 15s\n",
      "2500:\tlearn: 1.6479938\ttest: 1.7523822\tbest: 1.7523822 (2500)\ttotal: 2m 35s\tremaining: 23m 16s\n",
      "5000:\tlearn: 1.4186856\ttest: 1.5986719\tbest: 1.5986719 (5000)\ttotal: 5m 12s\tremaining: 20m 51s\n",
      "7500:\tlearn: 1.2647818\ttest: 1.5038648\tbest: 1.5038648 (7500)\ttotal: 7m 51s\tremaining: 18m 18s\n",
      "10000:\tlearn: 1.1450968\ttest: 1.4347252\tbest: 1.4347252 (10000)\ttotal: 10m 30s\tremaining: 15m 44s\n",
      "12500:\tlearn: 1.0502672\ttest: 1.3846320\tbest: 1.3846320 (12500)\ttotal: 13m 10s\tremaining: 13m 10s\n",
      "15000:\tlearn: 0.9701398\ttest: 1.3453289\tbest: 1.3453289 (15000)\ttotal: 15m 51s\tremaining: 10m 34s\n",
      "17500:\tlearn: 0.9036532\ttest: 1.3160769\tbest: 1.3160769 (17500)\ttotal: 18m 33s\tremaining: 7m 57s\n",
      "20000:\tlearn: 0.8456900\ttest: 1.2926668\tbest: 1.2926660 (19997)\ttotal: 21m 15s\tremaining: 5m 18s\n",
      "22500:\tlearn: 0.7943018\ttest: 1.2726610\tbest: 1.2726610 (22500)\ttotal: 23m 57s\tremaining: 2m 39s\n",
      "24999:\tlearn: 0.7484372\ttest: 1.2557471\tbest: 1.2557471 (24999)\ttotal: 26m 39s\tremaining: 0us\n",
      "bestTest = 1.25574707\n",
      "bestIteration = 24999\n",
      "Shrink model to first 25000 iterations.\n",
      "After 5 test_CV = 1.241 | train_CV = 0.755 | 0.487 CPU times: user 43min 44s, sys: 1h 43min 30s, total: 2h 27min 14s\n",
      "Wall time: 2h 15min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "oof = np.zeros(len(train_X))\n",
    "train_score = []\n",
    "fold_idxs = []\n",
    "# if PREDICTION: \n",
    "predictions = np.zeros(len(test_X))\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "#run model\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X,train_y.values)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "    fold_idxs.append(val_idx)\n",
    "\n",
    "    X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "    y_tr, y_val = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n",
    "\n",
    "    model = CatBoostRegressor(n_estimators=25000, verbose=-1, objective=\"MAE\", loss_function=\"MAE\", boosting_type=\"Ordered\", task_type=\"GPU\")\n",
    "    model.fit(X_tr, \n",
    "              y_tr, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "#               eval_metric='mae',\n",
    "              verbose=2500, \n",
    "              early_stopping_rounds=500)\n",
    "    oof[val_idx] = model.predict(X_val)\n",
    "\n",
    "    #feature importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = train_columns\n",
    "    fold_importance_df[\"importance\"] = model.feature_importances_[:len(train_columns)]\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    #predictions\n",
    "#     if PREDICTION:\n",
    "\n",
    "    predictions += model.predict(test_X[train_columns]) / folds.n_splits\n",
    "    train_score.append(model.best_score_['learn'][\"MAE\"])\n",
    "\n",
    "cv_score = mean_absolute_error(train_y, oof)\n",
    "print(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>2.806046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>5.183179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>4.890522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>8.580695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>6.781291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         2.806046\n",
       "1  seg_0012b5         5.183179\n",
       "2  seg_00184e         4.890522\n",
       "3  seg_003339         8.580695\n",
       "4  seg_0042cc         6.781291"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = str(datetime.date.today())\n",
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv')\n",
    "\n",
    "submission[\"time_to_failure\"] = predictions\n",
    "submission.to_csv(f'CatBoost_{today}_test_{cv_score:.3f}_train_{np.mean(train_score):.3f}.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim=10):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(256, activation=\"relu\", input_dim=input_dim))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(96, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dropout(0.3))\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) #'rmsprop'\n",
    "    model.compile(optimizer=optimizer,loss='mae')\n",
    "    return model\n",
    "\n",
    "patience = 50\n",
    "call_ES = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=1, mode='auto', baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00287: early stopping\n",
      "loss: 0.884 | val_loss: 1.382 | diff: 0.498\n",
      "fold 1\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00428: early stopping\n",
      "loss: 0.816 | val_loss: 1.401 | diff: 0.586\n",
      "fold 2\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00284: early stopping\n",
      "loss: 0.910 | val_loss: 1.459 | diff: 0.549\n",
      "fold 3\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00279: early stopping\n",
      "loss: 0.897 | val_loss: 1.457 | diff: 0.560\n",
      "fold 4\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00424: early stopping\n",
      "loss: 0.815 | val_loss: 1.420 | diff: 0.604\n",
      "After 5 test_CV = 1.339 | train_CV = 0.864 | 0.475 CPU times: user 2h 29min 31s, sys: 12min 9s, total: 2h 41min 41s\n",
      "Wall time: 2h 8min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "NN_oof = np.zeros(len(train_X))\n",
    "train_score = []\n",
    "fold_idxs = []\n",
    "\n",
    "NN_predictions = np.zeros(len(test_X))\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X,train_y.values)):\n",
    "    strLog = \"fold {}\".format(fold_)\n",
    "    print(strLog)\n",
    "    fold_idxs.append(val_idx)\n",
    "    \n",
    "    X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "    y_tr, y_val = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n",
    "    model = create_model(train_X.shape[-1])\n",
    "    model.fit(X_tr, y_tr, epochs=500, batch_size=32, verbose=0, callbacks=[call_ES,], validation_data=[X_val, y_val]) #\n",
    "    \n",
    "    NN_oof[val_idx] = model.predict(X_val)[:,0]\n",
    "    \n",
    "    NN_predictions += model.predict(test_X[train_columns])[:,0] / folds.n_splits\n",
    "    history = model.history.history\n",
    "    tr_loss = history[\"loss\"]\n",
    "    val_loss = history[\"val_loss\"]\n",
    "    print(f\"loss: {tr_loss[-patience]:.3f} | val_loss: {val_loss[-patience]:.3f} | diff: {val_loss[-patience]-tr_loss[-patience]:.3f}\")\n",
    "    train_score.append(tr_loss[-patience])\n",
    "#     break\n",
    "    \n",
    "cv_score = mean_absolute_error(train_y, NN_oof)\n",
    "print(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>2.612691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>4.810834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>3.973062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>7.660580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>6.638792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         2.612691\n",
       "1  seg_0012b5         4.810834\n",
       "2  seg_00184e         3.973062\n",
       "3  seg_003339         7.660580\n",
       "4  seg_0042cc         6.638792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = str(datetime.date.today())\n",
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv')\n",
    "\n",
    "submission[\"time_to_failure\"] = NN_predictions\n",
    "submission.to_csv(f'NN_{today}_test_{cv_score:.3f}_train_{np.mean(train_score):.3f}.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_parameters = {'tournament_size': 17, 'population_size': 4000, 'p_crossover': 0.8, 'generations': 18}\n",
    "# function_set = ('add', 'sub', 'mul', 'div', \"sqrt\", \"log\", \"max\", \"min\", \"sin\", \"cos\", \"tan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # n_fold = 5\n",
    "# folds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "\n",
    "# GPL_oof = np.zeros(len(train_X))\n",
    "# GPL_predictions = np.zeros(len(test_X))\n",
    "# train_score = []\n",
    "\n",
    "# for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_X,train_y.values)):\n",
    "#     strLog = \"fold {}\".format(fold_)\n",
    "#     print(strLog)\n",
    "    \n",
    "#     X_tr, X_val = train_X[train_columns].iloc[trn_idx], train_X[train_columns].iloc[val_idx]\n",
    "#     y_tr, y_val = train_y.iloc[trn_idx], train_y.iloc[val_idx]\n",
    "    \n",
    "#     model = SymbolicRegressor(**best_parameters, stopping_criteria=0.0,const_range=(-1.0, 1.0), init_depth=(2, 6), init_method='half and half', \n",
    "#                           function_set=function_set, metric='mean absolute error', parsimony_coefficient=0.001,\n",
    "#                           p_subtree_mutation=0.01, p_hoist_mutation=0.01, p_point_mutation=0.01, \n",
    "#                           p_point_replace=0.05, max_samples=1.0, feature_names=None, \n",
    "#                           warm_start=False, low_memory=False, n_jobs=-1, verbose=1, random_state=42)\n",
    "    \n",
    "#     model.fit(X_tr, y_tr) #\n",
    "    \n",
    "#     GPL_oof[val_idx] = model.predict(X_val)\n",
    "#     GPL_predictions += model.predict(test_X[train_columns]) / folds.n_splits\n",
    "    \n",
    "#     train_score.append(model.run_details_[\"best_fitness\"][-1])\n",
    "# #     break\n",
    "    \n",
    "# cv_score = mean_absolute_error(train_y, GPL_oof)\n",
    "# print(f\"After {n_fold} test_CV = {cv_score:.3f} | train_CV = {np.mean(train_score):.3f} | {cv_score-np.mean(train_score):.3f}\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = str(datetime.date.today())\n",
    "# submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv')\n",
    "\n",
    "# submission[\"time_to_failure\"] = GPL_predictions\n",
    "# submission.to_csv(f'GPL_{today}_test_{cv_score:.3f}_train_{np.mean(train_score):.3f}.csv', index=False)\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>2.856751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>4.189392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>5.538267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>9.051419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>7.099581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         2.856751\n",
       "1  seg_0012b5         4.189392\n",
       "2  seg_00184e         5.538267\n",
       "3  seg_003339         9.051419\n",
       "4  seg_0042cc         7.099581"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scirpus_prediction = pd.read_csv(\"../input/andrews-new-script-plus-a-genetic-program-model/gpI.csv\")\n",
    "Scirpus_prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_id</th>\n",
       "      <th>time_to_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seg_00030f</td>\n",
       "      <td>2.758496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seg_0012b5</td>\n",
       "      <td>4.727802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seg_00184e</td>\n",
       "      <td>4.800617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seg_003339</td>\n",
       "      <td>8.430898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seg_0042cc</td>\n",
       "      <td>6.839888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       seg_id  time_to_failure\n",
       "0  seg_00030f         2.758496\n",
       "1  seg_0012b5         4.727802\n",
       "2  seg_00184e         4.800617\n",
       "3  seg_003339         8.430898\n",
       "4  seg_0042cc         6.839888"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = str(datetime.date.today())\n",
    "submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv')\n",
    "\n",
    "submission[\"time_to_failure\"] = (predictions+NN_predictions+Scirpus_prediction.time_to_failure.values)/3\n",
    "submission.to_csv(f'FINAL_{today}_submission.csv', index=False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
