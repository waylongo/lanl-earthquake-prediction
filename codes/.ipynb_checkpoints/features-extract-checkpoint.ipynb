{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - import libraries and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape is (629145480, 2)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('../input/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})\n",
    "print('training data shape is ' + str(train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7241dfd2fb409a8eb07e80d7f68c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41933), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a training file with simple derived features\n",
    "rows = 150000\n",
    "gap = int(rows / 10)\n",
    "segments = int(np.floor(train.shape[0] / gap)) - 10\n",
    "\n",
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    \n",
    "    sta = np.cumsum(x ** 2)\n",
    "\n",
    "    # Convert to float\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "\n",
    "    # Copy for LTA\n",
    "    lta = sta.copy()\n",
    "\n",
    "    # Compute the STA and the LTA\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "\n",
    "    # Pad zeros\n",
    "    sta[:length_lta - 1] = 0\n",
    "\n",
    "    # Avoid division by zero by setting zero values to tiny float\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "\n",
    "    return sta / lta\n",
    "\n",
    "X_tr = pd.DataFrame(index=range(segments), dtype=np.float64)\n",
    "\n",
    "y_tr = pd.DataFrame(index=range(segments), dtype=np.float64, columns=['time_to_failure'])\n",
    "\n",
    "total_mean = train['acoustic_data'].mean()\n",
    "total_std = train['acoustic_data'].std()\n",
    "total_max = train['acoustic_data'].max()\n",
    "total_min = train['acoustic_data'].min()\n",
    "total_sum = train['acoustic_data'].sum()\n",
    "total_abs_sum = np.abs(train['acoustic_data']).sum()\n",
    "\n",
    "def calc_change_rate(x):\n",
    "    change = (np.diff(x) / x[:-1]).values\n",
    "    change = change[np.nonzero(change)[0]]\n",
    "    change = change[~np.isnan(change)]\n",
    "    change = change[change != -np.inf]\n",
    "    change = change[change != np.inf]\n",
    "    return np.mean(change)\n",
    "\n",
    "for segment in tqdm_notebook(range(segments)):\n",
    "    seg = train.iloc[segment*gap:segment*gap+rows]\n",
    "    x = pd.Series(seg['acoustic_data'].values)\n",
    "    y = seg['time_to_failure'].values[-1]\n",
    "    \n",
    "    y_tr.loc[segment, 'time_to_failure'] = y\n",
    "    X_tr.loc[segment, 'mean'] = x.mean()\n",
    "    X_tr.loc[segment, 'std'] = x.std()\n",
    "    X_tr.loc[segment, 'max'] = x.max()\n",
    "    X_tr.loc[segment, 'min'] = x.min()\n",
    "    \n",
    "    X_tr.loc[segment, 'mean_change_abs'] = np.mean(np.diff(x))\n",
    "    X_tr.loc[segment, 'mean_change_rate'] = calc_change_rate(x)\n",
    "    X_tr.loc[segment, 'abs_max'] = np.abs(x).max()\n",
    "    X_tr.loc[segment, 'abs_min'] = np.abs(x).min()\n",
    "    \n",
    "    X_tr.loc[segment, 'std_first_50000'] = x[:50000].std()\n",
    "    X_tr.loc[segment, 'std_last_50000'] = x[-50000:].std()\n",
    "    X_tr.loc[segment, 'std_first_10000'] = x[:10000].std()\n",
    "    X_tr.loc[segment, 'std_last_10000'] = x[-10000:].std()\n",
    "    \n",
    "    X_tr.loc[segment, 'avg_first_50000'] = x[:50000].mean()\n",
    "    X_tr.loc[segment, 'avg_last_50000'] = x[-50000:].mean()\n",
    "    X_tr.loc[segment, 'avg_first_10000'] = x[:10000].mean()\n",
    "    X_tr.loc[segment, 'avg_last_10000'] = x[-10000:].mean()\n",
    "    \n",
    "    X_tr.loc[segment, 'min_first_50000'] = x[:50000].min()\n",
    "    X_tr.loc[segment, 'min_last_50000'] = x[-50000:].min()\n",
    "    X_tr.loc[segment, 'min_first_10000'] = x[:10000].min()\n",
    "    X_tr.loc[segment, 'min_last_10000'] = x[-10000:].min()\n",
    "    \n",
    "    X_tr.loc[segment, 'max_first_50000'] = x[:50000].max()\n",
    "    X_tr.loc[segment, 'max_last_50000'] = x[-50000:].max()\n",
    "    X_tr.loc[segment, 'max_first_10000'] = x[:10000].max()\n",
    "    X_tr.loc[segment, 'max_last_10000'] = x[-10000:].max()\n",
    "    \n",
    "    X_tr.loc[segment, 'max_to_min'] = x.max() / np.abs(x.min())\n",
    "    X_tr.loc[segment, 'max_to_min_diff'] = x.max() - np.abs(x.min())\n",
    "    X_tr.loc[segment, 'count_big'] = len(x[np.abs(x) > 500])\n",
    "    X_tr.loc[segment, 'sum'] = x.sum()\n",
    "    \n",
    "    X_tr.loc[segment, 'mean_change_rate_first_50000'] = calc_change_rate(x[:50000])\n",
    "    X_tr.loc[segment, 'mean_change_rate_last_50000'] = calc_change_rate(x[-50000:])\n",
    "    X_tr.loc[segment, 'mean_change_rate_first_10000'] = calc_change_rate(x[:10000])\n",
    "    X_tr.loc[segment, 'mean_change_rate_last_10000'] = calc_change_rate(x[-10000:])\n",
    "    \n",
    "    X_tr.loc[segment, 'q95'] = np.quantile(x, 0.95)\n",
    "    X_tr.loc[segment, 'q99'] = np.quantile(x, 0.99)\n",
    "    X_tr.loc[segment, 'q05'] = np.quantile(x, 0.05)\n",
    "    X_tr.loc[segment, 'q01'] = np.quantile(x, 0.01)\n",
    "    \n",
    "    X_tr.loc[segment, 'abs_q95'] = np.quantile(np.abs(x), 0.95)\n",
    "    X_tr.loc[segment, 'abs_q99'] = np.quantile(np.abs(x), 0.99)\n",
    "    X_tr.loc[segment, 'abs_q05'] = np.quantile(np.abs(x), 0.05)\n",
    "    X_tr.loc[segment, 'abs_q01'] = np.quantile(np.abs(x), 0.01)\n",
    "    \n",
    "    X_tr.loc[segment, 'trend'] = add_trend_feature(x)\n",
    "    X_tr.loc[segment, 'abs_trend'] = add_trend_feature(x, abs_values=True)\n",
    "    X_tr.loc[segment, 'abs_mean'] = np.abs(x).mean()\n",
    "    X_tr.loc[segment, 'abs_std'] = np.abs(x).std()\n",
    "    \n",
    "    X_tr.loc[segment, 'mad'] = x.mad()\n",
    "    X_tr.loc[segment, 'kurt'] = x.kurtosis()\n",
    "    X_tr.loc[segment, 'skew'] = x.skew()\n",
    "    X_tr.loc[segment, 'med'] = x.median()\n",
    "    \n",
    "    X_tr.loc[segment, 'Hilbert_mean'] = np.abs(hilbert(x)).mean()\n",
    "    X_tr.loc[segment, 'Hann_window_mean'] = (convolve(x, hann(150), mode='same') / sum(hann(150))).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta1_mean'] = classic_sta_lta(x, 500, 10000).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta2_mean'] = classic_sta_lta(x, 5000, 100000).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta3_mean'] = classic_sta_lta(x, 3333, 6666).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta4_mean'] = classic_sta_lta(x, 10000, 25000).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta5_mean'] = classic_sta_lta(x, 50, 1000).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta6_mean'] = classic_sta_lta(x, 100, 5000).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta7_mean'] = classic_sta_lta(x, 333, 666).mean()\n",
    "    X_tr.loc[segment, 'classic_sta_lta8_mean'] = classic_sta_lta(x, 4000, 10000).mean()\n",
    "    X_tr.loc[segment, 'Moving_average_700_mean'] = x.rolling(window=700).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_tr.loc[segment, 'exp_Moving_average_300_mean'] = (ewma(x, span=300).mean()).mean(skipna=True)\n",
    "    X_tr.loc[segment, 'exp_Moving_average_3000_mean'] = ewma(x, span=3000).mean().mean(skipna=True)\n",
    "    X_tr.loc[segment, 'exp_Moving_average_30000_mean'] = ewma(x, span=30000).mean().mean(skipna=True)\n",
    "    no_of_std = 3\n",
    "    X_tr.loc[segment, 'MA_700MA_std_mean'] = x.rolling(window=700).std().mean()\n",
    "    X_tr.loc[segment,'MA_700MA_BB_high_mean'] = (X_tr.loc[segment, 'Moving_average_700_mean'] + no_of_std * X_tr.loc[segment, 'MA_700MA_std_mean']).mean()\n",
    "    X_tr.loc[segment,'MA_700MA_BB_low_mean'] = (X_tr.loc[segment, 'Moving_average_700_mean'] - no_of_std * X_tr.loc[segment, 'MA_700MA_std_mean']).mean()\n",
    "    X_tr.loc[segment, 'MA_400MA_std_mean'] = x.rolling(window=400).std().mean()\n",
    "    X_tr.loc[segment,'MA_400MA_BB_high_mean'] = (X_tr.loc[segment, 'Moving_average_700_mean'] + no_of_std * X_tr.loc[segment, 'MA_400MA_std_mean']).mean()\n",
    "    X_tr.loc[segment,'MA_400MA_BB_low_mean'] = (X_tr.loc[segment, 'Moving_average_700_mean'] - no_of_std * X_tr.loc[segment, 'MA_400MA_std_mean']).mean()\n",
    "    X_tr.loc[segment, 'MA_1000MA_std_mean'] = x.rolling(window=1000).std().mean()\n",
    "    X_tr.drop('Moving_average_700_mean', axis=1, inplace=True)\n",
    "    \n",
    "    X_tr.loc[segment, 'iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n",
    "    X_tr.loc[segment, 'q999'] = np.quantile(x,0.999)\n",
    "    X_tr.loc[segment, 'q001'] = np.quantile(x,0.001)\n",
    "    X_tr.loc[segment, 'ave10'] = stats.trim_mean(x, 0.1)\n",
    "\n",
    "    for windows in [10, 100, 1000]:\n",
    "        x_roll_std = x.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X_tr.loc[segment, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X_tr.loc[segment, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X_tr.loc[segment, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X_tr.loc[segment, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X_tr.loc[segment, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X_tr.loc[segment, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X_tr.loc[segment, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X_tr.loc[segment, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X_tr.loc[segment, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X_tr.loc[segment, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X_tr.loc[segment, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X_tr.loc[segment, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X_tr.loc[segment, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X_tr.loc[segment, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X_tr.loc[segment, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X_tr.loc[segment, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_tr.loc[segment, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_tr.loc[segment, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_tr.loc[segment, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_tr.loc[segment, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X_tr.loc[segment, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X_tr.loc[segment, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41933 samples in new train data and 138 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f'{X_tr.shape[0]} samples in new train data and {X_tr.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q05_roll_std_100                0.643947\n",
       "q01_roll_std_100                0.642459\n",
       "q05_roll_std_10                 0.637893\n",
       "q01_roll_std_10                 0.629222\n",
       "q01_roll_std_1000               0.605072\n",
       "q05_roll_std_1000               0.604552\n",
       "min_roll_std_1000               0.546119\n",
       "mean_change_rate                0.537195\n",
       "mean_change_rate_first_50000    0.509624\n",
       "mean_change_rate_last_50000     0.500950\n",
       "iqr                             0.497183\n",
       "classic_sta_lta6_mean           0.455809\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(X_tr.corrwith(y_tr['time_to_failure'])).sort_values(ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classic_sta_lta5_mean\n",
      "classic_sta_lta7_mean\n"
     ]
    }
   ],
   "source": [
    "means_dict = {}\n",
    "for col in X_tr.columns:\n",
    "    if X_tr[col].isnull().any():\n",
    "        print(col)\n",
    "        mean_value = X_tr.loc[X_tr[col] != -np.inf, col].mean()\n",
    "        X_tr.loc[X_tr[col] == -np.inf, col] = mean_value\n",
    "        X_tr[col] = X_tr[col].fillna(mean_value)\n",
    "        means_dict[col] = mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "X_test = pd.DataFrame(columns=X_tr.columns, dtype=np.float64, index=submission.index)\n",
    "plt.figure(figsize=(22, 16))\n",
    "\n",
    "for i, seg_id in enumerate(tqdm_notebook(X_test.index)):\n",
    "    seg = pd.read_csv('../input/test/' + seg_id + '.csv')\n",
    "    \n",
    "    x = pd.Series(seg['acoustic_data'].values)\n",
    "    X_test.loc[seg_id, 'mean'] = x.mean()\n",
    "    X_test.loc[seg_id, 'std'] = x.std()\n",
    "    X_test.loc[seg_id, 'max'] = x.max()\n",
    "    X_test.loc[seg_id, 'min'] = x.min()\n",
    "        \n",
    "    X_test.loc[seg_id, 'mean_change_abs'] = np.mean(np.diff(x))\n",
    "    X_test.loc[seg_id, 'mean_change_rate'] = calc_change_rate(x)\n",
    "    X_test.loc[seg_id, 'abs_max'] = np.abs(x).max()\n",
    "    X_test.loc[seg_id, 'abs_min'] = np.abs(x).min()\n",
    "    \n",
    "    X_test.loc[seg_id, 'std_first_50000'] = x[:50000].std()\n",
    "    X_test.loc[seg_id, 'std_last_50000'] = x[-50000:].std()\n",
    "    X_test.loc[seg_id, 'std_first_10000'] = x[:10000].std()\n",
    "    X_test.loc[seg_id, 'std_last_10000'] = x[-10000:].std()\n",
    "    \n",
    "    X_test.loc[seg_id, 'avg_first_50000'] = x[:50000].mean()\n",
    "    X_test.loc[seg_id, 'avg_last_50000'] = x[-50000:].mean()\n",
    "    X_test.loc[seg_id, 'avg_first_10000'] = x[:10000].mean()\n",
    "    X_test.loc[seg_id, 'avg_last_10000'] = x[-10000:].mean()\n",
    "    \n",
    "    X_test.loc[seg_id, 'min_first_50000'] = x[:50000].min()\n",
    "    X_test.loc[seg_id, 'min_last_50000'] = x[-50000:].min()\n",
    "    X_test.loc[seg_id, 'min_first_10000'] = x[:10000].min()\n",
    "    X_test.loc[seg_id, 'min_last_10000'] = x[-10000:].min()\n",
    "    \n",
    "    X_test.loc[seg_id, 'max_first_50000'] = x[:50000].max()\n",
    "    X_test.loc[seg_id, 'max_last_50000'] = x[-50000:].max()\n",
    "    X_test.loc[seg_id, 'max_first_10000'] = x[:10000].max()\n",
    "    X_test.loc[seg_id, 'max_last_10000'] = x[-10000:].max()\n",
    "    \n",
    "    X_test.loc[seg_id, 'max_to_min'] = x.max() / np.abs(x.min())\n",
    "    X_test.loc[seg_id, 'max_to_min_diff'] = x.max() - np.abs(x.min())\n",
    "    X_test.loc[seg_id, 'count_big'] = len(x[np.abs(x) > 500])\n",
    "    X_test.loc[seg_id, 'sum'] = x.sum()\n",
    "    \n",
    "    X_test.loc[seg_id, 'mean_change_rate_first_50000'] = calc_change_rate(x[:50000])\n",
    "    X_test.loc[seg_id, 'mean_change_rate_last_50000'] = calc_change_rate(x[-50000:])\n",
    "    X_test.loc[seg_id, 'mean_change_rate_first_10000'] = calc_change_rate(x[:10000])\n",
    "    X_test.loc[seg_id, 'mean_change_rate_last_10000'] = calc_change_rate(x[-10000:])\n",
    "    \n",
    "    X_test.loc[seg_id, 'q95'] = np.quantile(x,0.95)\n",
    "    X_test.loc[seg_id, 'q99'] = np.quantile(x,0.99)\n",
    "    X_test.loc[seg_id, 'q05'] = np.quantile(x,0.05)\n",
    "    X_test.loc[seg_id, 'q01'] = np.quantile(x,0.01)\n",
    "    \n",
    "    X_test.loc[seg_id, 'abs_q95'] = np.quantile(np.abs(x), 0.95)\n",
    "    X_test.loc[seg_id, 'abs_q99'] = np.quantile(np.abs(x), 0.99)\n",
    "    X_test.loc[seg_id, 'abs_q05'] = np.quantile(np.abs(x), 0.05)\n",
    "    X_test.loc[seg_id, 'abs_q01'] = np.quantile(np.abs(x), 0.01)\n",
    "    \n",
    "    X_test.loc[seg_id, 'trend'] = add_trend_feature(x)\n",
    "    X_test.loc[seg_id, 'abs_trend'] = add_trend_feature(x, abs_values=True)\n",
    "    X_test.loc[seg_id, 'abs_mean'] = np.abs(x).mean()\n",
    "    X_test.loc[seg_id, 'abs_std'] = np.abs(x).std()\n",
    "    \n",
    "    X_test.loc[seg_id, 'mad'] = x.mad()\n",
    "    X_test.loc[seg_id, 'kurt'] = x.kurtosis()\n",
    "    X_test.loc[seg_id, 'skew'] = x.skew()\n",
    "    X_test.loc[seg_id, 'med'] = x.median()\n",
    "    \n",
    "    X_test.loc[seg_id, 'Hilbert_mean'] = np.abs(hilbert(x)).mean()\n",
    "    X_test.loc[seg_id, 'Hann_window_mean'] = (convolve(x, hann(150), mode='same') / sum(hann(150))).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta1_mean'] = classic_sta_lta(x, 500, 10000).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta2_mean'] = classic_sta_lta(x, 5000, 100000).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta3_mean'] = classic_sta_lta(x, 3333, 6666).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta4_mean'] = classic_sta_lta(x, 10000, 25000).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta5_mean'] = classic_sta_lta(x, 50, 1000).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta6_mean'] = classic_sta_lta(x, 100, 5000).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta7_mean'] = classic_sta_lta(x, 333, 666).mean()\n",
    "    X_test.loc[seg_id, 'classic_sta_lta8_mean'] = classic_sta_lta(x, 4000, 10000).mean()\n",
    "    X_test.loc[seg_id, 'Moving_average_700_mean'] = x.rolling(window=700).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_test.loc[seg_id, 'exp_Moving_average_300_mean'] = (ewma(x, span=300).mean()).mean(skipna=True)\n",
    "    X_test.loc[seg_id, 'exp_Moving_average_3000_mean'] = ewma(x, span=3000).mean().mean(skipna=True)\n",
    "    X_test.loc[seg_id, 'exp_Moving_average_30000_mean'] = ewma(x, span=30000).mean().mean(skipna=True)\n",
    "    no_of_std = 3\n",
    "    X_test.loc[seg_id, 'MA_700MA_std_mean'] = x.rolling(window=700).std().mean()\n",
    "    X_test.loc[seg_id,'MA_700MA_BB_high_mean'] = (X_test.loc[seg_id, 'Moving_average_700_mean'] + no_of_std * X_test.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[seg_id,'MA_700MA_BB_low_mean'] = (X_test.loc[seg_id, 'Moving_average_700_mean'] - no_of_std * X_test.loc[seg_id, 'MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[seg_id, 'MA_400MA_std_mean'] = x.rolling(window=400).std().mean()\n",
    "    X_test.loc[seg_id,'MA_400MA_BB_high_mean'] = (X_test.loc[seg_id, 'Moving_average_700_mean'] + no_of_std * X_test.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[seg_id,'MA_400MA_BB_low_mean'] = (X_test.loc[seg_id, 'Moving_average_700_mean'] - no_of_std * X_test.loc[seg_id, 'MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[seg_id, 'MA_1000MA_std_mean'] = x.rolling(window=1000).std().mean()\n",
    "    X_test.drop('Moving_average_700_mean', axis=1, inplace=True)\n",
    "    \n",
    "    X_test.loc[seg_id, 'iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n",
    "    X_test.loc[seg_id, 'q999'] = np.quantile(x,0.999)\n",
    "    X_test.loc[seg_id, 'q001'] = np.quantile(x,0.001)\n",
    "    X_test.loc[seg_id, 'ave10'] = stats.trim_mean(x, 0.1)\n",
    "    \n",
    "    for windows in [10, 100, 1000]:\n",
    "        x_roll_std = x.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = x.rolling(windows).mean().dropna().values\n",
    "        \n",
    "        X_test.loc[seg_id, 'ave_roll_std_' + str(windows)] = x_roll_std.mean()\n",
    "        X_test.loc[seg_id, 'std_roll_std_' + str(windows)] = x_roll_std.std()\n",
    "        X_test.loc[seg_id, 'max_roll_std_' + str(windows)] = x_roll_std.max()\n",
    "        X_test.loc[seg_id, 'min_roll_std_' + str(windows)] = x_roll_std.min()\n",
    "        X_test.loc[seg_id, 'q01_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.01)\n",
    "        X_test.loc[seg_id, 'q05_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.05)\n",
    "        X_test.loc[seg_id, 'q95_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.95)\n",
    "        X_test.loc[seg_id, 'q99_roll_std_' + str(windows)] = np.quantile(x_roll_std, 0.99)\n",
    "        X_test.loc[seg_id, 'av_change_abs_roll_std_' + str(windows)] = np.mean(np.diff(x_roll_std))\n",
    "        X_test.loc[seg_id, 'av_change_rate_roll_std_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_std) / x_roll_std[:-1]))[0])\n",
    "        X_test.loc[seg_id, 'abs_max_roll_std_' + str(windows)] = np.abs(x_roll_std).max()\n",
    "        \n",
    "        X_test.loc[seg_id, 'ave_roll_mean_' + str(windows)] = x_roll_mean.mean()\n",
    "        X_test.loc[seg_id, 'std_roll_mean_' + str(windows)] = x_roll_mean.std()\n",
    "        X_test.loc[seg_id, 'max_roll_mean_' + str(windows)] = x_roll_mean.max()\n",
    "        X_test.loc[seg_id, 'min_roll_mean_' + str(windows)] = x_roll_mean.min()\n",
    "        X_test.loc[seg_id, 'q01_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_test.loc[seg_id, 'q05_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_test.loc[seg_id, 'q95_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_test.loc[seg_id, 'q99_roll_mean_' + str(windows)] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_test.loc[seg_id, 'av_change_abs_roll_mean_' + str(windows)] = np.mean(np.diff(x_roll_mean))\n",
    "        X_test.loc[seg_id, 'av_change_rate_roll_mean_' + str(windows)] = np.mean(np.nonzero((np.diff(x_roll_mean) / x_roll_mean[:-1]))[0])\n",
    "        X_test.loc[seg_id, 'abs_max_roll_mean_' + str(windows)] = np.abs(x_roll_mean).max()\n",
    "    \n",
    "    if i < 12:\n",
    "        plt.subplot(6, 4, i + 1)\n",
    "        plt.plot(seg['acoustic_data'])\n",
    "        plt.title(seg_id)\n",
    "\n",
    "for col in X_test.columns:\n",
    "    if X_test[col].isnull().any():\n",
    "        X_test.loc[X_test[col] == -np.inf, col] = means_dict[col]\n",
    "        X_test[col] = X_test[col].fillna(means_dict[col])\n",
    "        \n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### save features\n",
    "# X_tr.to_csv('train_features.csv', index=False)\n",
    "# X_test.to_csv('test_features.csv', index=False)\n",
    "# y_tr.to_csv('train_features_label.csv', index=False)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_tr)\n",
    "# X_train_scaled = pd.DataFrame(scaler.transform(X_tr), columns=X_tr.columns)\n",
    "# X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
