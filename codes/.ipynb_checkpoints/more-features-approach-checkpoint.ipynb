{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn import svm\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.ensemble import ExtraTreesRegressor, AdaBoostRegressor\n",
    "\n",
    "import scipy as sc\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import librosa, librosa.display\n",
    "import builtins\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import eli5\n",
    "import shap\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "import artgor_utils\n",
    "\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# setting up altair\n",
    "workaround = artgor_utils.prepare_altair()\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround,\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from tensorflow import keras\n",
    "from gplearn.genetic import SymbolicRegressor\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_0 = pd.read_csv(\"../input/lanl-masters-features-creating-0/train_X_features_865.csv\")\n",
    "train_X_1 = pd.read_csv(\"../input/lanl-masters-features-creating-1/train_X_features_865.csv\")\n",
    "y_0 = pd.read_csv(\"../input/lanl-masters-features-creating-0/train_y.csv\", index_col=False,  header=None)\n",
    "y_1 = pd.read_csv(\"../input/lanl-masters-features-creating-1/train_y.csv\", index_col=False,  header=None)\n",
    "X_test = pd.read_csv(\"../input/lanl-masters-features-creating-0/test_X_features_10.csv\")\n",
    "del X_test[\"seg_id\"]\n",
    "\n",
    "\n",
    "X = pd.concat([train_X_0, train_X_1], axis=0)\n",
    "X = X.reset_index(drop=True)\n",
    "\n",
    "y = pd.concat([y_0, y_1], axis=0)\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_columns = X.columns\n",
    "\n",
    "X[train_columns] = scaler.fit_transform(X[train_columns])\n",
    "X_test[train_columns] = scaler.transform(X_test[train_columns])\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'objective': 'gamma',\n",
    "    'max_depth': -1,\n",
    "    'learning_rate': 0.03,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"subsample_freq\": 5,\n",
    "    \"subsample\": 0.85,\n",
    "    \"bagging_seed\": 11,\n",
    "    \"metric\": 'mae',\n",
    "    \"verbosity\": -1,\n",
    "    'reg_alpha': 0.13,\n",
    "    'reg_lambda': 0.36,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# parameter_grid = {'n_estimators': [30, 50, 80, 100, 120, 160, 200], 'max_depth': [5, 10, 15]}\n",
    "parameter_grid = {'n_estimators': [50, 100, 150], 'max_depth': [10]}\n",
    "\n",
    "grid_search = GridSearchCV(rfr,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(**grid_search.best_params_)\n",
    "result_dict_rfr = artgor_utils.train_model_regression(X,\n",
    "                                                      X_test,\n",
    "                                                      y,\n",
    "                                                      params=params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='sklearn',\n",
    "                                                      model=rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "# parameter_grid = {'n_neighbors': [10, 40, 60, 80, 100, 150],\n",
    "#                 'weights':['uniform', 'distance']\n",
    "# }\n",
    "parameter_grid = {'n_neighbors': [30, 50, 80],\n",
    "                 'weights':['distance']\n",
    "                 }\n",
    "\n",
    "grid_search = GridSearchCV(knn,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsRegressor(**grid_search.best_params_)\n",
    "result_dict_knn = artgor_utils.train_model_regression(X,\n",
    "                                                      X_test,\n",
    "                                                      y,\n",
    "                                                      params=params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='sklearn',\n",
    "                                                      model=knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. extra tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "etr = ExtraTreesRegressor()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'n_estimators': [500, 700, 1000, 1300],\n",
    "#     'max_depth': [5, 10, 15]\n",
    "# }\n",
    "parameter_grid = {\n",
    "    'n_estimators': [500, 1000],\n",
    "    'max_depth': [10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(rfr,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr = ExtraTreesRegressor(**grid_search.best_params_)\n",
    "result_dict_etr = artgor_utils.train_model_regression(X,\n",
    "                                                      X_test,\n",
    "                                                      y,\n",
    "                                                      params=params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='sklearn',\n",
    "                                                      model=etr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ada boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "adr = AdaBoostRegressor()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'n_estimators': [10, 50, 80, 100, 200],\n",
    "#      'learning_rate':[0.01, 0.03, 0.1, 0.3]\n",
    "# }\n",
    "\n",
    "parameter_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate':[0.03]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(adr,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr = AdaBoostRegressor(**grid_search.best_params_)\n",
    "result_dict_adr = artgor_utils.train_model_regression(X,\n",
    "                                                      X_test,\n",
    "                                                      y,\n",
    "                                                      params=params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='sklearn',\n",
    "                                                      model=adr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nusvr = NuSVR()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'gamma': ['scale','auto'],\n",
    "#     'nu': [0.5, 0.6, 0.7,0.8, 0.9],\n",
    "#     'C': [1, 3, 5, 7,10],\n",
    "#     'tol': [0.01, 0.003, 0.001]\n",
    "# }\n",
    "parameter_grid = {\n",
    "    'gamma': ['auto'],\n",
    "    'nu': [0.7],\n",
    "    'C': [3],\n",
    "    'tol': [0.001]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(nusvr,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr = NuSVR(**grid_search.best_params_)\n",
    "result_dict_nusvr = artgor_utils.train_model_regression(X,\n",
    "                                                        X_test,\n",
    "                                                        y,\n",
    "                                                        params=params,\n",
    "                                                        folds=folds,\n",
    "                                                        model_type='sklearn',\n",
    "                                                        model=nusvr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8));\n",
    "scores_df = pd.DataFrame({'RandomForestRegressor': result_dict_rfr['scores']})\n",
    "scores_df['KNN'] = result_dict_knn['scores']\n",
    "scores_df['ExtraTreesRegressor'] = result_dict_etr['scores']\n",
    "scores_df['AdaBoostRegressor'] = result_dict_adr['scores']\n",
    "scores_df['NuSVR'] = result_dict_nusvr['scores']\n",
    "\n",
    "sns.boxplot(data=scores_df);\n",
    "plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. light gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lightgmb = lgb.LGBMRegressor()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'num_leaves': [64, 128, 256],\n",
    "#     'min_child_samples': [32, 64],\n",
    "#     'objective': ['gamma'],\n",
    "#     'max_depth': [-1],\n",
    "#     'learning_rate': [0.003, 0.01, 0.03, 0.1],\n",
    "#     \"boosting_type\": ['gbdt'],\n",
    "#     \"subsample_freq\": [5],\n",
    "#     \"subsample\": [0.85],\n",
    "#     \"bagging_seed\": [11],\n",
    "#     \"metric\": ['mae'],\n",
    "#     \"verbosity\": [-1],\n",
    "#     'reg_alpha': [0.13],\n",
    "#     'reg_lambda': [0.36],\n",
    "#     'colsample_bytree': [0.2]\n",
    "# }\n",
    "\n",
    "parameter_grid = {\n",
    "    'num_leaves': [128],\n",
    "    'min_child_samples': [64],\n",
    "    'objective': ['gamma'],\n",
    "    'max_depth': [-1],\n",
    "    'learning_rate': [0.03],\n",
    "    \"boosting_type\": ['gbdt'],\n",
    "    \"subsample_freq\": [5],\n",
    "    \"subsample\": [0.85],\n",
    "    \"bagging_seed\": [11],\n",
    "    \"metric\": ['mae'],\n",
    "    \"verbosity\": [-1],\n",
    "    'reg_alpha': [0.1],\n",
    "    'reg_lambda': [0.3],\n",
    "    'colsample_bytree': [0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lightgmb,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(X, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lightgmb = lgb.LGBMRegressor(**grid_search.best_params_)\n",
    "result_dict_lgb = artgor_utils.train_model_regression(\n",
    "    X=X,\n",
    "    X_test=X_test,\n",
    "    y=y,\n",
    "    params=grid_search.best_params_,\n",
    "    folds=folds,\n",
    "    model_type='lgb',\n",
    "    eval_metric='mae',\n",
    "    plot_feature_importance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 16,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective': 'gpu:reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'silent': True,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "result_dict_xgb = artgor_utils.train_model_regression(X=X,\n",
    "                                                      X_test=X_test,\n",
    "                                                      y=y,\n",
    "                                                      params=xgb_params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. cat boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "result_dict_cat = artgor_utils.train_model_regression(X=X,\n",
    "                                                     X_test=X_test,\n",
    "                                                     y=y,\n",
    "                                                     params=params,\n",
    "                                                     folds=folds,\n",
    "                                                     model_type='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv', index_col='seg_id')\n",
    "submission['time_to_failure'] = (\n",
    "    result_dict_rfr['prediction'] + result_dict_knn['prediction'] +\n",
    "    result_dict_etr['prediction'] + result_dict_adr['prediction'] +\n",
    "    result_dict_nusvr['prediction'] + result_dict_lgb['prediction'] +\n",
    "    result_dict_xgb['prediction'] + result_dict_cat['prediction']) / 8\n",
    "print(submission.head())\n",
    "# submission.to_csv('average_blending.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - create new features sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack = np.vstack([\n",
    "    result_dict_rfr['oof'], result_dict_knn['oof'], result_dict_etr['oof'],\n",
    "    result_dict_adr['oof'], result_dict_nusvr['oof'], result_dict_lgb['oof'],\n",
    "    result_dict_xgb['oof'], result_dict_cat['oof']\n",
    "]).transpose()\n",
    "train_stack = pd.DataFrame(\n",
    "    train_stack,\n",
    "    columns=['rfr', 'knn', 'etr', 'adr', 'nusvr', 'lgb', 'xgb', 'cat'])\n",
    "\n",
    "test_stack = np.vstack([\n",
    "    result_dict_rfr['prediction'], result_dict_knn['prediction'],\n",
    "    result_dict_etr['prediction'], result_dict_adr['prediction'],\n",
    "    result_dict_nusvr['prediction'], result_dict_lgb['prediction'],\n",
    "    result_dict_xgb['prediction'], result_dict_cat['prediction']\n",
    "]).transpose()\n",
    "test_stack = pd.DataFrame(\n",
    "    test_stack,\n",
    "    columns=['rfr', 'knn', 'etr', 'adr', 'nusvr', 'lgb', 'xgb', 'cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - lgm stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lightgmb = lgb.LGBMRegressor()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'num_leaves': [8, 16],\n",
    "#     'min_child_samples': [8, 16],\n",
    "#     'objective': ['gamma'],\n",
    "#     'max_depth': [-1],\n",
    "#     'learning_rate': [0.01, 0.03, 0.1],\n",
    "#     \"boosting_type\": ['gbdt'],\n",
    "#     \"subsample_freq\": [5],\n",
    "#     \"subsample\": [0.85],\n",
    "#     \"bagging_seed\": [11],\n",
    "#     \"metric\": ['mae'],\n",
    "#     \"verbosity\": [-1],\n",
    "#     'reg_alpha': [0.03, 0.1, 0.3],\n",
    "# }\n",
    "\n",
    "parameter_grid = {\n",
    "    'num_leaves': [16],\n",
    "    'min_child_samples': [16],\n",
    "    'objective': ['gamma'],\n",
    "    'max_depth': [4, 8],\n",
    "    'learning_rate': [0.03],\n",
    "    \"boosting_type\": ['gbdt'],\n",
    "    \"subsample_freq\": [5],\n",
    "    \"subsample\": [0.85],\n",
    "    \"bagging_seed\": [11],\n",
    "    \"metric\": ['mae'],\n",
    "    \"verbosity\": [-1],\n",
    "    'reg_alpha': [0.03],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lightgmb,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(train_stack, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_lgb_stack = artgor_utils.train_model_regression(\n",
    "    X=train_stack,\n",
    "    X_test=test_stack,\n",
    "    y=y,\n",
    "    params=grid_search.best_params_,\n",
    "    folds=folds,\n",
    "    model_type='lgb',\n",
    "    eval_metric='mae',\n",
    "    plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.03,\n",
    "    'max_depth': 4,\n",
    "    'subsample': 0.85,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'objective': 'gpu:reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'silent': True,\n",
    "    'tree_method': 'gpu_hist'\n",
    "}\n",
    "result_dict_xgb_stack = artgor_utils.train_model_regression(X=train_stack,\n",
    "                                                      X_test=test_stack,\n",
    "                                                      y=y,\n",
    "                                                      params=xgb_params,\n",
    "                                                      folds=folds,\n",
    "                                                      model_type='xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - cat boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "result_dict_cat_stack = artgor_utils.train_model_regression(X=train_stack,\n",
    "                                                     X_test=test_stack,\n",
    "                                                     y=y,\n",
    "                                                     params=params,\n",
    "                                                     folds=folds,\n",
    "                                                     model_type='cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light gbm final stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - create second features sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stack_second = np.vstack([\n",
    "    result_dict_lgb_stack['oof'], result_dict_xgb_stack['oof'], result_dict_cat_stack['oof']\n",
    "]).transpose()\n",
    "train_stack_second = pd.DataFrame(\n",
    "    train_stack,\n",
    "    columns=['lgb', 'xgb','cat'])\n",
    "\n",
    "test_stack_second = np.vstack([\n",
    "    result_dict_lgb_stack['prediction'], result_dict_xgb_stack['prediction'],\n",
    "    result_dict_cat_stack['prediction']\n",
    "]).transpose()\n",
    "test_stack_second = pd.DataFrame(\n",
    "    test_stack,\n",
    "    columns=['lgb', 'xgb','cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - final lgb stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lightgmb = lgb.LGBMRegressor()\n",
    "\n",
    "# parameter_grid = {\n",
    "#     'num_leaves': [4, 8,16],\n",
    "#     'min_child_samples': [8, 16],\n",
    "#     'objective': ['gamma'],\n",
    "#     'max_depth': [4, 8],\n",
    "#     'learning_rate': [0.01, 0.03],\n",
    "#     \"boosting_type\": ['gbdt'],\n",
    "#     \"subsample_freq\": [5],\n",
    "#     \"subsample\": [0.85],\n",
    "#     \"bagging_seed\": [11],\n",
    "#     \"metric\": ['mae'],\n",
    "#     \"verbosity\": [-1],\n",
    "#     'reg_alpha': [0.03, 0.1],\n",
    "# }\n",
    "\n",
    "parameter_grid = {\n",
    "    'num_leaves': [16],\n",
    "    'min_child_samples': [16],\n",
    "    'objective': ['gamma'],\n",
    "    'max_depth': [4],\n",
    "    'learning_rate': [0.03],\n",
    "    \"boosting_type\": ['gbdt'],\n",
    "    \"subsample_freq\": [5],\n",
    "    \"subsample\": [0.85],\n",
    "    \"bagging_seed\": [11],\n",
    "    \"metric\": ['mae'],\n",
    "    \"verbosity\": [-1],\n",
    "    'reg_alpha': [0.03],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(lightgmb,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=folds,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=12)\n",
    "grid_search.fit(train_stack, y)\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lightgmb = lgb.LGBMRegressor(**grid_search.best_params_)\n",
    "result_dict_lgb_stack_final = artgor_utils.train_model_regression(\n",
    "    X=train_stack_second,\n",
    "    X_test=test_stack_second,\n",
    "    y=y,\n",
    "    params=grid_search.best_params_,\n",
    "    folds=folds,\n",
    "    model_type='lgb',\n",
    "    eval_metric='mae',\n",
    "    plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['time_to_failure'] = result_dict_lgb_stack_final['prediction']\n",
    "print(submission.head())\n",
    "submission.to_csv('good-features-second-stacking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
